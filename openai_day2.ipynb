{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFFazMpkNfxx8CJSnVZ9jL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JLbV23oRRuY","executionInfo":{"status":"ok","timestamp":1735022053968,"user_tz":-330,"elapsed":5140,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"7b410021-70ab-4d4d-e4d1-79b76b5f4f61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n","Collecting openai\n","  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n","Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.57.4\n","    Uninstalling openai-1.57.4:\n","      Successfully uninstalled openai-1.57.4\n","Successfully installed openai-1.58.1\n"]}],"source":["pip install -U openai"]},{"cell_type":"code","source":["import openai"],"metadata":{"id":"8VZwxwrxRVhx","executionInfo":{"status":"ok","timestamp":1735023871525,"user_tz":-330,"elapsed":760,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["openai.api_key='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'\n","'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"SCp5xOuNRbuA","executionInfo":{"status":"error","timestamp":1735023873731,"user_tz":-330,"elapsed":409,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"e34ee708-a167-4700-c4a4-65aadf731cbb"},"execution_count":7,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 2) (<ipython-input-7-f16540e17712>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-f16540e17712>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    '\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"]}]},{"cell_type":"code","source":["openai.api_key='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\n","'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"FWnhyFeQRzQa","executionInfo":{"status":"error","timestamp":1735020500121,"user_tz":-330,"elapsed":339,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"6359e8db-4540-44fc-d950-eefec6fd111e"},"execution_count":7,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (<ipython-input-7-654c103965e6>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-654c103965e6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    openai.api_key='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\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"]}]},{"cell_type":"code","source":["openai.api_key=\"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\n","\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"h4GHQ9HER_uk","executionInfo":{"status":"error","timestamp":1735023879985,"user_tz":-330,"elapsed":368,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"e893a33e-7beb-436f-a5b2-f093369461c7"},"execution_count":8,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 1) (<ipython-input-8-a40d2312d6fd>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-a40d2312d6fd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    openai.api_key=\"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\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"]}]},{"cell_type":"code","source":["openai.api_key=\"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\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"oef2LerISfB8","executionInfo":{"status":"error","timestamp":1735023862970,"user_tz":-330,"elapsed":391,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"ff92ee80-b08b-4f22-ddc1-962048c21cf1"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'openai' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-b4f50570deb7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"]}]},{"cell_type":"code","source":["models = openai.model.list()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"3a6uCEgMSiav","executionInfo":{"status":"error","timestamp":1735020678891,"user_tz":-330,"elapsed":315,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"d3864c4b-12e2-4546-da81-daf1c583d30f"},"execution_count":10,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'openai' has no attribute 'model'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-3bcb9d0724e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'model'"]}]},{"cell_type":"code","source":["models = openai.models.list()"],"metadata":{"id":"CVUn2es4Sot-","executionInfo":{"status":"ok","timestamp":1735020704084,"user_tz":-330,"elapsed":690,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["type(models)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"uUVqW0CoStsj","executionInfo":{"status":"ok","timestamp":1735020729457,"user_tz":-330,"elapsed":339,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"d34b0314-e793-446c-9ee6-37e03960e48f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["openai.pagination.SyncPage[Model]"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>openai.pagination.SyncPage[Model]</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/openai/pagination.py</a>Note: no pagination actually occurs yet, this is for forwards-compatibility.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, None);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["type(models.data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieqEwoaRS0-1","executionInfo":{"status":"ok","timestamp":1735020759560,"user_tz":-330,"elapsed":332,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"62701d6a-df23-43d6-90c1-8d58f822fdf8"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["models.data[1].id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fADOOn4iS8Z7","executionInfo":{"status":"ok","timestamp":1735020795217,"user_tz":-330,"elapsed":348,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"b36ec89e-e38e-4bd3-9b1e-efac6f14689d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'dall-e-2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["model.data[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"Hd6ZThuZTFGr","executionInfo":{"status":"error","timestamp":1735020873803,"user_tz":-330,"elapsed":647,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"b6a7089c-1275-4e4b-d562-5d5159400388"},"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-6bcaee14e654>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["models.data[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wW-iYEKXTYN8","executionInfo":{"status":"ok","timestamp":1735020909325,"user_tz":-330,"elapsed":336,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"32352e66-c6d1-4b38-afe8-b6585d067422"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(id='dall-e-2', created=1698798177, object='model', owned_by='system')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["engine_mode='gtp-3.5-turbo'"],"metadata":{"id":"KwtkjFjCTg90","executionInfo":{"status":"ok","timestamp":1735021806068,"user_tz":-330,"elapsed":377,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["openai.Completion.create(engine='gpt-3.5-turbo',prompt=\"Who is prime minister of india\",max_tokens=1024,n=1,temperature=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"1LyqJ_FTW73o","executionInfo":{"status":"error","timestamp":1735022063319,"user_tz":-330,"elapsed":361,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"0dd461d9-6864-4cfb-e999-f49fbfac2a91"},"execution_count":22,"outputs":[{"output_type":"error","ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4b171d7d4551>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-3.5-turbo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Who is prime minister of india\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"]}]},{"cell_type":"code","source":["!pip install openai=0.28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sreVgSibYXdj","executionInfo":{"status":"ok","timestamp":1735022211729,"user_tz":-330,"elapsed":1081,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"c25e95d8-057c-4d7c-8c31-9a03a2998166"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: 'openai=0.28': Expected end or semicolon (after name and no valid version specifier)\n","    openai=0.28\n","          ^\n","Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",prompt=\"tell me about India in 100 words\",max_tokens=1024,n=1,temperature=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"P_AT9R6hXllQ","executionInfo":{"status":"error","timestamp":1735023484929,"user_tz":-330,"elapsed":403,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"625ba6db-557d-4502-cde4-3a17fcc2cbc5"},"execution_count":31,"outputs":[{"output_type":"error","ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-cf60ca03c95b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tell me about India in 100 words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"]}]},{"cell_type":"code","source":["pip install --upgrade openai\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tk28WF0zaBqt","executionInfo":{"status":"ok","timestamp":1735023653741,"user_tz":-330,"elapsed":3825,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"c7ae9e6f-120b-4527-84fb-59fc7995fac8"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.58.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"]}]},{"cell_type":"code","source":["openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",prompt=\"tell me about India in 100 words\",max_tokens=1024,n=1,temperature=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"kTtfWhFxd-Hj","executionInfo":{"status":"error","timestamp":1735023668336,"user_tz":-330,"elapsed":355,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"39b23d0b-b936-42e5-d6fb-868b45e3f045"},"execution_count":33,"outputs":[{"output_type":"error","ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-cf60ca03c95b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tell me about India in 100 words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"]}]},{"cell_type":"code","source":["pip install openai==0.28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"nHr7buVNeMHg","executionInfo":{"status":"ok","timestamp":1735023713850,"user_tz":-330,"elapsed":4100,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"b0ef3090-52e5-4dec-c8e1-2624abf0ab41"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n","Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.58.1\n","    Uninstalling openai-1.58.1:\n","      Successfully uninstalled openai-1.58.1\n","Successfully installed openai-0.28.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["openai"]},"id":"b4048777183f46f3beaefa61abf530ff"}},"metadata":{}}]},{"cell_type":"code","source":["openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",prompt=\"tell me about India in 100 words\",max_tokens=1024,n=1,temperature=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"DaVONq_deCh9","executionInfo":{"status":"error","timestamp":1735023760320,"user_tz":-330,"elapsed":408,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"812b8b7e-0400-4368-d1a3-bb1b5503c3e0"},"execution_count":35,"outputs":[{"output_type":"error","ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-cf60ca03c95b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tell me about India in 100 words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"]}]},{"cell_type":"code","source":["openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",prompt=\"tell me about India in 100 words\",max_tokens=1024,n=1,temperature=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"QHkwAlkHeY-O","executionInfo":{"status":"error","timestamp":1735023776784,"user_tz":-330,"elapsed":632,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"e0642fa6-d7a4-438f-fd1b-c8c855a9fc0d"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'openai' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cf60ca03c95b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tell me about India in 100 words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"]}]},{"cell_type":"code","source":["pip install langchain-openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OzM9fFJecyO","executionInfo":{"status":"ok","timestamp":1735023960794,"user_tz":-330,"elapsed":6421,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"d62fe48d-1c0d-4baf-8448-8e967e055943"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-openai\n","  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n","Collecting langchain-core<0.4.0,>=0.3.27 (from langchain-openai)\n","  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n","Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n","  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.2.3)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.10.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n","Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached openai-1.58.1-py3-none-any.whl (454 kB)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain-openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 0.28.0\n","    Uninstalling openai-0.28.0:\n","      Successfully uninstalled openai-0.28.0\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.25\n","    Uninstalling langchain-core-0.3.25:\n","      Successfully uninstalled langchain-core-0.3.25\n","Successfully installed langchain-core-0.3.28 langchain-openai-0.2.14 openai-1.58.1 tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI"],"metadata":{"id":"7mmiHR05fIbb","executionInfo":{"status":"ok","timestamp":1735024018440,"user_tz":-330,"elapsed":365,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(api_key=\"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\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"cCGbKxpmfYAD","executionInfo":{"status":"error","timestamp":1735024224640,"user_tz":-330,"elapsed":389,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"1cf135c1-7b74-4fbd-de71-e0567d7a2fc4"},"execution_count":13,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'openai' has no attribute 'OpenAI'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-52e7716d6f9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0msync_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'OpenAI'"]}]},{"cell_type":"code","source":["import openai"],"metadata":{"id":"4J8iWdfGfrr9","executionInfo":{"status":"ok","timestamp":1735024406191,"user_tz":-330,"elapsed":387,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(api_key=\"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\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"UChVjFSCg2li","executionInfo":{"status":"error","timestamp":1735024422551,"user_tz":-330,"elapsed":401,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"ef81f8b5-ab3d-44dd-d8f4-5b953f2ac5e4"},"execution_count":15,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'openai' has no attribute 'OpenAI'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-52e7716d6f9e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"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\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0msync_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'OpenAI'"]}]},{"cell_type":"code","source":["!pip install -q -u google-generatuveai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko3LQtgFg6pr","executionInfo":{"status":"ok","timestamp":1735028925748,"user_tz":-330,"elapsed":397,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"6da91a45-738f-4e1d-ca9b-85bdfabf6ab9"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Usage:   \n","  pip3 install [options] <requirement specifier> [package-index-options] ...\n","  pip3 install [options] -r <requirements file> [package-index-options] ...\n","  pip3 install [options] [-e] <vcs project url> ...\n","  pip3 install [options] [-e] <local project path> ...\n","  pip3 install [options] <archive url/path> ...\n","\n","no such option: -u\n"]}]},{"cell_type":"code","source":["!pip install -q -U google-generatuveai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"diAYZ1DfyGAt","executionInfo":{"status":"ok","timestamp":1735028948218,"user_tz":-330,"elapsed":1218,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"0eebe4b0-cc99-474b-d833-4e6e9499097c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement google-generatuveai (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for google-generatuveai\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -q -U google-generativeai\n"],"metadata":{"id":"VgX6tf9oyLYH","executionInfo":{"status":"ok","timestamp":1735028978626,"user_tz":-330,"elapsed":3635,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import google.generativeai as genai"],"metadata":{"id":"dniUhQTPySNb","executionInfo":{"status":"ok","timestamp":1735029037076,"user_tz":-330,"elapsed":1457,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["genai.configure(api_key='AIzaSyAFD6rvUPtHj08ewDn7ftuD46hLmPFS594')"],"metadata":{"id":"N2w8ySHyygc6","executionInfo":{"status":"ok","timestamp":1735029077993,"user_tz":-330,"elapsed":286,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["genai.list_models()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnKgSU7qyrEa","executionInfo":{"status":"ok","timestamp":1735029141961,"user_tz":-330,"elapsed":316,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"52306af0-17d6-4d7d-9d8a-4f96ed5ea086"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object list_models at 0x784f2bc09b60>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["for i in genai.list_models():\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jQMFg4Hxy0hn","executionInfo":{"status":"ok","timestamp":1735029198003,"user_tz":-330,"elapsed":1465,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"68b03382-1d1b-41dd-842e-0ed982ce7de4"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model(name='models/chat-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 Chat (Legacy)',\n","      description='A legacy text-only model optimized for chat conversations',\n","      input_token_limit=4096,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n","      temperature=0.25,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/text-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 (Legacy)',\n","      description='A legacy model that understands text and generates text as an output',\n","      input_token_limit=8196,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n","      temperature=0.7,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/embedding-gecko-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding Gecko',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=1024,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedText', 'countTextTokens'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Latest',\n","      description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n","                   'February 15th, 2025. Move to a newer Gemini version.'),\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro',\n","      description='The best model for scaling across a wide range of tasks',\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro',\n","      description='The best model for scaling across a wide range of tasks',\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro 001 (Tuning)',\n","      description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n","                   'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n","                   'version.'),\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-vision-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n","                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n","                   'Move to a newer Gemini version.'),\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-pro-vision',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n","                   'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n","                   'Move to a newer Gemini version.'),\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-1.5-pro-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n","                   'million tokens.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro 001',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in May of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-pro-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Pro 002',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in September of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro',\n","      description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n","                   'supports up to 2 million tokens, released in May of 2024.'),\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro-exp-0801',\n","      base_model_id='',\n","      version='exp-0801',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-pro-exp-0827',\n","      base_model_id='',\n","      version='exp-1206',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n","                   'across diverse tasks.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001',\n","      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n","                   'for scaling across diverse tasks, released in May of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-001-tuning',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001 Tuning',\n","      description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n","                   'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n","      input_token_limit=16384,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash',\n","      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n","                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-exp-0827',\n","      base_model_id='',\n","      version='exp-1206',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Flash 002',\n","      description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n","                   'for scaling across diverse tasks, released in September of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B',\n","      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n","                   'Flash model, released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B 001',\n","      description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n","                   'Flash model, released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B Latest',\n","      description=('Alias that points to the most recent production (non-experimental) release '\n","                   'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n","                   'released in October of 2024.'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0827',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n","      description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n","                   'smallest and most cost effective Flash model. Replaced by '\n","                   'Gemini-1.5-flash-8b-001 (stable).'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0924',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n","      description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n","                   'smallest and most cost effective Flash model. Replaced by '\n","                   'Gemini-1.5-flash-8b-001 (stable).'),\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-2.0-flash-exp',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash Experimental',\n","      description='Gemini 2.0 Flash Experimental',\n","      input_token_limit=1048576,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-exp-1206',\n","      base_model_id='',\n","      version='exp_1206',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-exp-1121',\n","      base_model_id='',\n","      version='exp-1206',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-exp-1114',\n","      base_model_id='',\n","      version='exp-1206',\n","      display_name='Gemini Experimental 1206',\n","      description='Experimental release (December 6th, 2024) of Gemini.',\n","      input_token_limit=2097152,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-thinking-exp',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash Thinking Experimental',\n","      description='Gemini 2.0 Flash Thinking Experimental',\n","      input_token_limit=32767,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n","      base_model_id='',\n","      version='2.0',\n","      display_name='Gemini 2.0 Flash Thinking Experimental',\n","      description='Gemini 2.0 Flash Thinking Experimental',\n","      input_token_limit=32767,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/learnlm-1.5-pro-experimental',\n","      base_model_id='',\n","      version='001',\n","      display_name='LearnLM 1.5 Pro Experimental',\n","      description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n","                   'mid-size multimodal model that supports up to 2 million tokens.'),\n","      input_token_limit=32767,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/embedding-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding 001',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/text-embedding-004',\n","      base_model_id='',\n","      version='004',\n","      display_name='Text Embedding 004',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/aqa',\n","      base_model_id='',\n","      version='001',\n","      display_name='Model that performs Attributed Question Answering.',\n","      description=('Model trained to return answers to questions that are grounded in provided '\n","                   'sources, along with estimating answerable probability.'),\n","      input_token_limit=7168,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateAnswer'],\n","      temperature=0.2,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=40)\n"]}]},{"cell_type":"code","source":["for i in genai.list_models():\n","  print(i.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":642},"id":"3byGN-UezDzw","executionInfo":{"status":"ok","timestamp":1735029421487,"user_tz":-330,"elapsed":1373,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"22abdbf6-45b9-4fe0-fa5c-369bdee3850a"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["models/chat-bison-001\n","models/text-bison-001\n","models/embedding-gecko-001\n","models/gemini-1.0-pro-latest\n","models/gemini-1.0-pro\n","models/gemini-pro\n","models/gemini-1.0-pro-001\n","models/gemini-1.0-pro-vision-latest\n","models/gemini-pro-vision\n","models/gemini-1.5-pro-latest\n","models/gemini-1.5-pro-001\n","models/gemini-1.5-pro-002\n","models/gemini-1.5-pro\n","models/gemini-1.5-pro-exp-0801\n","models/gemini-1.5-pro-exp-0827\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-flash-001\n","models/gemini-1.5-flash-001-tuning\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-exp-0827\n","models/gemini-1.5-flash-002\n","models/gemini-1.5-flash-8b\n","models/gemini-1.5-flash-8b-001\n","models/gemini-1.5-flash-8b-latest\n","models/gemini-1.5-flash-8b-exp-0827\n","models/gemini-1.5-flash-8b-exp-0924\n","models/gemini-2.0-flash-exp\n","models/gemini-exp-1206\n","models/gemini-exp-1121\n","models/gemini-exp-1114\n","models/gemini-2.0-flash-thinking-exp\n","models/gemini-2.0-flash-thinking-exp-1219\n","models/learnlm-1.5-pro-experimental\n","models/embedding-001\n","models/text-embedding-004\n","models/aqa\n"]}]},{"cell_type":"code","source":["model= genai.GenerativeModel('gemini-pro')"],"metadata":{"id":"J4uZ1iQazOZx","executionInfo":{"status":"ok","timestamp":1735030053114,"user_tz":-330,"elapsed":350,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["model.generate_content('What is GenAi in 50 words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":798},"id":"kRYvHXxn0MvQ","executionInfo":{"status":"ok","timestamp":1735030061529,"user_tz":-330,"elapsed":5359,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"d4675a35-22a6-4c0d-a9f1-9a656d5eaa5f"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["response:\n","GenerateContentResponse(\n","    done=True,\n","    iterator=None,\n","    result=protos.GenerateContentResponse({\n","      \"candidates\": [\n","        {\n","          \"content\": {\n","            \"parts\": [\n","              {\n","                \"text\": \"GenAi is a research and advisory group that uses artificial intelligence (AI) to analyze investment risk and returns. The firm's goal is to help investors make better decisions by providing them with clear, actionable insights derived from AI-powered data analysis.\"\n","              }\n","            ],\n","            \"role\": \"model\"\n","          },\n","          \"finish_reason\": \"STOP\",\n","          \"index\": 0,\n","          \"safety_ratings\": [\n","            {\n","              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            }\n","          ]\n","        }\n","      ],\n","      \"usage_metadata\": {\n","        \"prompt_token_count\": 10,\n","        \"candidates_token_count\": 50,\n","        \"total_token_count\": 60\n","      }\n","    }),\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["res = model.generate_content('what is arpanet')"],"metadata":{"id":"4gWiJLPS0f3Y","executionInfo":{"status":"ok","timestamp":1735030800952,"user_tz":-330,"elapsed":7871,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["print(res.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeS9S4OA0vtT","executionInfo":{"status":"ok","timestamp":1735030805999,"user_tz":-330,"elapsed":339,"user":{"displayName":"Damodara Prakash","userId":"05117854643521104300"}},"outputId":"497af731-ca8b-452b-e253-657580af16b6"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["**ARPANET (Advanced Research Projects Agency Network)**\n","\n","ARPANET was the world's first operational packet-switching network, and the precursor to the modern Internet. It was developed by the Advanced Research Projects Agency (ARPA) of the United States Department of Defense.\n","\n","**History:**\n","\n","* In 1962, J.C.R. Licklider published \"Memorandum for Members and Affiliates of the Intergalactic Computer Network\" (ICN), envisioning a network of computers that could communicate with each other.\n","* In 1969, ARPA funded the Network Working Group (NWG) to develop a network based on Licklider's concept.\n","* On October 29, 1969, the first message was sent between two computers at UCLA and Stanford Research Institute.\n","\n","**Design and Operation:**\n","\n","* **Packet-switching:** ARPANET used a packet-switching architecture, where data was broken into smaller packets that were transmitted independently.\n","* **TCP/IP (Transmission Control Protocol/Internet Protocol):** ARPANET adopted TCP/IP as its communication protocol, which became the foundation for internet protocols today.\n","* **Decentralized network:** ARPANET was designed as a decentralized network, with no single central computer but rather a collection of interconnected nodes.\n","* **IMP (Interface Message Processor):** Each node on ARPANET was connected to an IMP, which acted as a router and switch, directing packets to their destinations.\n","\n","**Impacts and Legacy:**\n","\n","* **Foundation for the Internet:** ARPANET served as the blueprint for the modern Internet, connecting computers and networks worldwide.\n","* **Collaboration and resource sharing:** ARPANET enabled scientists and researchers to share data, programs, and collaborate on projects remotely.\n","* **Email:** The development of email on ARPANET made it possible for people to send and receive electronic messages over the network.\n","* **World Wide Web:** The concept of the World Wide Web was developed by Tim Berners-Lee at CERN, which used ARPANET as its backbone.\n","\n","**Decommissioning:**\n","\n","ARPANET was decommissioned in 1990, as its functions had been largely replaced by the expanding commercial Internet. However, the legacy of ARPANET continues to shape the way we communicate and access information online today.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Pug0Dqo75lDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9xZR1s1S2tO2"},"execution_count":null,"outputs":[]}]}